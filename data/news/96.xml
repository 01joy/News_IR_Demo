<?xml version='1.0' encoding='utf-8'?>
<doc><id>96</id><url>http://news.sohu.com/20160107/n433709677.shtml</url><title>苹果Siri再次涉黄 说“发张照片”弹出不雅图片</title><datetime>2016-01-07 02:47:00</datetime><body>　　京华时报讯（记者古晓宇）苹果再次卷入涉黄风波。近期有用户发现，对着苹果Siri说“发张照片”，会自动搜索出不雅图片。不过昨天，记者发现，苹果已封堵住了这一系统bug。
　　这两天，在微博和微信上疯传，当对着iPhone或iPad使用语音控制的Siri功能说“发张照片”时，iPhone或iPad上会自动显示出6张照片，而且都是内容不雅的涉黄照片。这一信息在网上引发较高关注，不少人进行尝试，并上传了自己搜索出的不雅照片。
　　对这一问题，苹果官方客服给出的解释是，对Siri发出语音指令，Siri会利用苹果手机系统自带的搜索功能搜索相关信息，不雅图片很可能就是这样自动搜索出来的。苹果方面承认，根据“发张照片”的指令，搜索出不雅照片，可能是系统的bug，并表示会尽快予以处理。
　　昨天，记者进行了试验，当对着Siri说“发张照片”时，出现的提示为“在网上找不到‘发张’有关的资料”；而对Siri说“照片”时，则会自动打开本机的图片库。看起来，这个漏洞已得到封堵。
　　有网络技术人士表示，“发张照片”这一语音命令，本身并没有涉黄的语义或者暗示，而默认搜索出不雅照片，确实可以说是iOS系统本身存在的问题。不过，Siri本身不会生成照片，能搜索出来，说明这些照片本来就是在网络上存在的，表明一些网络内容提供方或者搜索引擎在内容管控上不够严格。
　　实际上，这不是苹果Siri第一次“涉黄”。公开报道显示，2012年10月，有网友称Siri可提供“三陪”场所信息，调查发现，用Siri搜索“三陪”等信息，确实可以找到一些涉黄的场所。很快，苹果公司将“三陪”等敏感信息列入屏蔽范围，此外，苹果公司还表示，屏蔽范围除“三陪”等涉黄信息外，还包括涉及暴力等违反中国法律的信息。</body></doc>